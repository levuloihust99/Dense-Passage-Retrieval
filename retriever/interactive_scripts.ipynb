{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 16:13:52.356445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2;1m2022-03-12 16:14:06,532 - faiss.loader - INFO: \u001b[0mLoading faiss with AVX2 support.\n",
      "\u001b[38;5;2;1m2022-03-12 16:14:06,533 - faiss.loader - INFO: \u001b[0mCould not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "\u001b[38;5;2;1m2022-03-12 16:14:06,533 - faiss.loader - INFO: \u001b[0mLoading faiss.\n",
      "\u001b[38;5;2;1m2022-03-12 16:14:06,603 - faiss.loader - INFO: \u001b[0mSuccessfully loaded faiss.\n"
     ]
    }
   ],
   "source": [
    "from scripts.python.nn.generate_embeddings import load_context_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFRobertaModel\n",
    "from transformers import PhobertTokenizer\n",
    "from libs.nn.modeling import DualEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at pretrained/vinai/phobert-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at pretrained/vinai/phobert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
      "Some layers from the model checkpoint at pretrained/vinai/phobert-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at pretrained/vinai/phobert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "query_encoder = TFRobertaModel.from_pretrained(\"pretrained/vinai/phobert-base\")\n",
    "context_encoder = TFRobertaModel.from_pretrained(\"pretrained/vinai/phobert-base\")\n",
    "dual_encoder = DualEncoder(query_encoder=query_encoder, context_encoder=context_encoder)\n",
    "tokenizer = PhobertTokenizer.from_pretrained(\"pretrained/vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"phạm_vi điều_chỉnh của luật đấu_thầu\"\n",
    "context = {\n",
    "    \"title\": \"trách_nhiệm của nhà_thầu kiểm_toán :\",\n",
    "    \"text\": \"nhà_thầu kiểm_toán , kiểm_toán_viên khi thực_hiện kiểm_toán quyết_toán dự_án hoàn_thành phải chấp_hành nguyên_tắc hoạt_động kiểm_toán độc_lập , có quyền_hạn , nghĩa_vụ và chịu trách_nhiệm theo quy_định của pháp_luật về kiểm_toán ;\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/v2/train_data.json\", \"r\") as reader:\n",
    "    data = json.load(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = data[10][\"positive_contexts\"][0]\n",
    "query = data[10][\"questions\"][0]\n",
    "hardneg_contexts = data[3200][\"positive_contexts\"][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.data_helpers.build_tfrecord import tokenize_batched_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_inputs = tokenize_batched_contexts(tokenizer, [context], 256)\n",
    "context_inputs = {\n",
    "    \"input_ids\": tf.convert_to_tensor(context_inputs[\"input_ids\"]),\n",
    "    \"attention_mask\": tf.convert_to_tensor(context_inputs[\"attention_mask\"])\n",
    "}\n",
    "# hardneg_contexts_inputs = tokenize_batched_contexts(tokenizer, hardneg_contexts, 256)\n",
    "# hardneg_contexts_inputs = {\n",
    "#     \"input_ids\": tf.convert_to_tensor(hardneg_contexts_inputs[\"input_ids\"]),\n",
    "#     \"attention_mask\": tf.convert_to_tensor(hardneg_contexts_inputs[\"attention_mask\"])\n",
    "# }\n",
    "query_inputs = tokenizer(query, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5bfcd923d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(model=dual_encoder)\n",
    "ckpt.restore(\"checkpoints/luffy/ckpt-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = query_encoder(**query_inputs, return_dict=True, training=False).last_hidden_state[:, 0, :]\n",
    "context_embedding = context_encoder(**context_inputs, return_dict=True, training=False).last_hidden_state[:, 0, :]\n",
    "# hardneg_context_embedding = context_encoder(**hardneg_contexts_inputs, return_dict=True, training=False).last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34.85981   -7.384517  -5.1384287 -5.1301684 -4.1229057]\n",
      "[1.0000000e+00 4.5032043e-19 4.2558480e-18 4.2911421e-18 1.1749563e-17]\n"
     ]
    }
   ],
   "source": [
    "# combine_context_embedding = tf.concat([context_embedding, hardneg_context_embedding], axis=0)\n",
    "# sim_matrix = tf.matmul(query_embedding, combine_context_embedding, transpose_b=True)\n",
    "# print(tf.squeeze(sim_matrix).numpy())\n",
    "# sim_probs = tf.nn.softmax(sim_matrix, axis=-1)\n",
    "# print(tf.squeeze(sim_probs).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=32.02346>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(query_embedding * context_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26296df0ccb529c0bfe4607d9bdbb6349995cbbf534dbfdb5e136cf3c3f67cbe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
